---
title: Chatbox AI 自动化测试项目详解
date: 2025-01-13T00:00:00+08:00
categories:
  - 简历
  - 项目经验
---

## 项目概述

**项目名称：** Chatbox AI 跨平台自动化测试框架
**项目时间：** 2024.XX - 至今
**担任角色：** 测试工程师 / 自动化测试负责人
**项目规模：** 桌面端 + 移动端，测试用例 XX 条，代码约 XX 行

---

## 项目背景

Chatbox AI 是一款智能对话助手应用，支持 **Electron 桌面端**（Windows/macOS）和 **移动端**（iOS/Android）。随着功能迭代加速，手工回归测试成本越来越高，主要痛点：

1. **回归耗时长**：全量手工回归需要 2-3 天
2. **多平台差异**：不同平台 UI 实现不同，重复测试工作量大
3. **遗漏风险高**：手工测试容易漏测边缘场景
4. **崩溃难定位**：偶发性崩溃难以复现和定位

---

## 技术栈

| 类型 | 技术选型 |
|------|----------|
| **测试框架** | Playwright + TypeScript |
| **移动端** | Appium + WebdriverIO |
| **辅助工具** | Python + PyAutoGUI + Tesseract OCR |
| **版本控制** | Git + GitHub |
| **CI/CD** | GitHub Actions / Jenkins（待补充） |

---

## 项目架构

### 设计模式

采用 **POM（Page Object Model）** 设计模式，实现分层架构：

```
framework/
├── base.ts                 # 基础应用类（启动、关闭、崩溃检测）
├── chatbox-actions.ts      # 核心业务操作（发消息、模型切换）
├── chatbox-settings.ts     # 设置页面操作封装
├── mobile-actions.ts       # 移动端操作封装
├── test-helper.ts          # 测试辅助工具（等待、截图）
└── constants.ts            # 常量定义
```

### 核心模块

#### 1. 基础应用管理（base.ts）

```typescript
// 核心能力
- 应用启动/关闭管理
- 进程状态监控
- 崩溃检测与恢复
- 版本号获取与验证
```

#### 2. 业务操作封装（chatbox-actions.ts）

```typescript
// 核心能力
- 发送/接收消息
- 模型选择器操作
- 所有模型遍历测试
- 会话管理
```

#### 3. 移动端支持（mobile-actions.ts）

```typescript
// 核心能力
- Android 设备连接
- 元素定位与操作
- 截图与状态检查
```

---

## 核心功能实现

### 1. 跨平台统一测试框架

**问题：** 桌面端和移动端使用不同的自动化工具，如何统一管理？

**解决方案：**
- 桌面端：使用 Playwright 的 Electron 模式，直接通过 `_electron` 启动
- 移动端：使用 Appium 连接 Android 设备
- 通过 **接口抽象** 实现测试用例的统一编写

```typescript
// 接口抽象示例
interface IChatboxActions {
    sendMessage(message: string): Promise<{ isTimeout: boolean }>;
    openModelSelector(): Promise<void>;
    getAllModels(): Promise<string[]>;
}

// 桌面端和移动端分别实现该接口
```

### 2. 崩溃监控与恢复机制

**问题：** 应用偶发性崩溃，普通 UI 自动化检测不到

**解决方案：** 设计三层检测机制

```typescript
// 检测层级
1. 进程检测：检查 Chatbox 进程是否存在
2. 窗口检测：检查应用窗口是否可访问
3. 元素检测：检查关键元素是否响应

// 崩溃处理
- 自动保存崩溃上下文（截图、日志、最后操作）
- 生成崩溃报告
- 尝试恢复或终止测试
```

### 3. DMG 自动安装测试

**问题：** 每次发版需要手动测试安装流程，耗时长且容易出错

**解决方案：** 实现自动化安装测试

```python
# 实现流程
1. 自动下载最新版本 DMG
2. 使用 AppleScript 模拟用户操作
3. 自动完成安装流程
4. 验证安装成功（版本号、启动）
5. 卸载清理
```

**效果：** 10 分钟手工测试 → 2 分钟自动化执行

### 4. 多模型遍历测试

**问题：** Chatbox 支持多个 AI 模型，需要逐一验证

**解决方案：** 自动遍历所有模型进行功能验证

```typescript
// 核心逻辑
1. 获取所有可用模型列表
2. 依次切换模型
3. 发送测试消息
4. 验证响应正常
5. 记录测试结果
```

---

## 测试类型覆盖

| 测试类型 | 覆盖内容 | 工具/方式 |
|----------|----------|-----------|
| **冒烟测试** | 核心功能快速验证 | 自动化 |
| **功能测试** | 完整业务流程 | 手工 + 自动化 |
| **回归测试** | 历史功能稳定性 | 自动化 |
| **兼容性测试** | 跨平台、跨版本 | 手工 |
| **专项测试** | 搜索、导出、性能 | 专项验证 |
| **崩溃测试** | 长时间稳定性 | 自动化监控 |

---

## 数据成果（待补充）

| 指标 | 当前值 |
|------|--------|
| 测试用例数 | __ 条 |
| 自动化覆盖率 | __ % |
| 回归时间节省 | 从 X 小时 → X 分钟 |
| 累计发现 Bug | __ 个 |
| 代码行数 | __ 行 |

---

## 遇到的难点与解决

### 难点 1：元素定位不稳定

**场景：** Electron 应用中，某些元素加载慢导致定位失败

**解决：**
- 使用智能等待策略：`waitForSelector` + 自定义超时
- 实现重试机制：失败后自动重试 3 次
- Fallback 方案：尝试多种定位方式

### 难点 2：测试数据管理

**场景：** 不同环境需要不同的测试数据

**解决：**
- 使用配置文件管理测试数据
- 环境变量切换环境
- 测试数据与代码分离

### 难点 3：测试用例维护成本

**场景：** UI 变化导致大量用例失效

**解决：**
- 采用 POM 设计模式，元素定位集中管理
- 使用稳定的定位方式（优先 data-testid）
- 定期维护和重构

---

## 个人贡献

1. **框架搭建**：从零设计并实现自动化测试框架
2. **用例编写**：编写 XX 条自动化测试用例，覆盖核心功能
3. **流程优化**：将手工回归时间从 X 天缩短到 X 小时
4. **质量提升**：累计发现 __ 个 Bug，其中包括 __ 个严重 Bug
5. **文档建设**：编写测试规范和最佳实践文档

---

## 后续规划

1. **CI/CD 集成**：将自动化测试集成到 CI/CD 流程
2. **测试报告优化**：生成详细的测试报告和趋势分析
3. **性能测试**：加入启动速度、内存占用等性能指标监控
4. **测试数据平台**：建立测试数据管理平台
